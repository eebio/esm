var documenterSearchIndex = {"docs":
[{"location":"plate_readers/compatibility/#Compatibility","page":"Compatibility","title":"Compatibility","text":"","category":"section"},{"location":"plate_readers/compatibility/#Verification","page":"Compatibility","title":"Verification","text":"Different plate reader machines format their outputs in different ways. To ensure compatibility with a plate reader format, we require data from different plate reader types. We then include this data within some of the ESM tests to ensure that the data is correctly parsed, and future changes do not break this functionality.\n\nSpectraMax was verified using data from a \"Molecular Devices SpectraMax iD5 multi-mode microplate reader (Serial: 375703621)\"\nBioTek was verfied using data from a \"BioTek Synergy neo2 multi-mode reader (Serial: 18071614)\"\nTecan was verified using data from a \"Tecan Infinite 200 Pro (Cat#: 30050303 Serial: 1906010638)\"\n\nIf you find that you are using any of these plate reader brands and your data is not being correctly parsed, please let us know by opening an issue on GitHub.","category":"section"},{"location":"plate_readers/compatibility/#Generic-tabular-data","page":"Compatibility","title":"Generic tabular data","text":"note: Note\nIf you are considering using the generic tabular data format because your plate reader is not supported, please open an issue on GitHub. You only need to upload a data file from your plate reader (one that you haven't editted), and tell us the plate reader model and we will cover the rest to ensure it is supported in future. Feel free to open an issue and then use the generic format if you don't want to wait.\n\nIf you can't use any of the automated imports above, maybe your plate reader isn't supported (see the note above) or the original files have been editted already and no longer parse correctly, then you can use the generic tabular data format.\n\nThis format involves creating a folder for your plate reader data, and storing your data in multiple .tsv or .csv files (one per channel), with the channel in the filename.\n\nFor an example for how the data looks in this format, see the pr_folder in our test directory. It has plate reader data for two channels, OD and flu stored as .tsv files.\n\nEach file should have a first row that is a header of column names, including \"time\" and \"temperature\", followed by well names. Times should be given in the hh:mm:ss format. Temperature should be given in celcius.","category":"section"},{"location":"plate_readers/fluorescence/#Fluorescence","page":"Fluorescence","title":"Fluorescence","text":"There are a variety of methods for calculating per cell fluorescence. Each method uses the fluorescence(data, Method()) function signature. These can be used either in the Julia ESM package diectly, or in the transformations in the Excel template.","category":"section"},{"location":"plate_readers/fluorescence/#RatioAtMaxGrowth","page":"Fluorescence","title":"RatioAtMaxGrowth","text":"todo: todo\nDescribe how the ratio at max growth method works.\n\nIt can be called using fluorescence(data, RatioAtMaxGrowth()).","category":"section"},{"location":"plate_readers/fluorescence/#Implementation-Details","page":"Fluorescence","title":"Implementation Details","text":"If you want to implement a new fluorescence method to be included in ESM, you need to:\n\nOpen a pull request with the following code changes\nDefine a new struct for your method type in src/methods.jl\nThe type of that struct is a subtype of AbstractFluorescenceMethod\nDefine a new method dispatch fluorescence(data, ::NameOfNewMethodType)\nDocument that method in the fluorescence documentation (this page)\n\nIf you are unsure how to do any of these steps, feel free to open an issue on GitHub asking for a new fluorescence method and explaining how the method should work.","category":"section"},{"location":"qpcr/#qpcr","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"plate_readers/growth_rate/#Growth-Rate","page":"Growth Rate","title":"Growth Rate","text":"There are a variety of methods for calculating growth rates (or doubling times). Each method uses the growth_rate(data, time_col, Method()) function signature (or doubling_time(data, time_col, Method())). These can be used either in the Julia ESM package diectly, or in the transformations in the Excel template.","category":"section"},{"location":"plate_readers/growth_rate/#Endpoints","page":"Growth Rate","title":"Endpoints","text":"The Endpoints method is the same as fitting an exponential curve y=Aexp(bt) to two points (start_time and end_time) and returning the growth rate b.\n\nb = fracln (od(t_textend)) - ln (od(t_textstart))t_textend - t_textstart\n\nIt can be called using growth_rate(data, time_col, Endpoints(start_time, end_time)) or doubling_time(data, time_col, Endpoints(start_time, end_time)). start_time and end_time are the start and end times of the exponential phase.","category":"section"},{"location":"plate_readers/growth_rate/#LinearOnLog","page":"Growth Rate","title":"LinearOnLog","text":"The LinearOnLog method log-transforms the data (removing any points ≤ 0), and then fits a straight line on all the data between start_time and end_time, returning the gradient of the line of best fit.\n\nIt can be called using growth_rate(data, time_col, LinearOnLog(start_time, end_time)) or doubling_time(data, time_col, LinearOnLog(start_time, end_time)). start_time and end_time are the start and end times of the exponential phase.","category":"section"},{"location":"plate_readers/growth_rate/#ExpOnLinear","page":"Growth Rate","title":"ExpOnLinear","text":"The ExpOnLinear method is similar to the LinearOnLog method. It fits the line y=Aexp(bt) through all the data between start_time and end_time. This means negative points aren't removed, and the residuals (during the curve fitting) are not log-transformed.\n\nIt can be called using growth_rate(data, time_col, ExpOnLinear(start_time, end_time)) or doubling_time(data, time_col, ExpOnLinear(start_time, end_time)). start_time and end_time are the start and end times of the exponential phase.","category":"section"},{"location":"plate_readers/growth_rate/#MovingWindow","page":"Growth Rate","title":"MovingWindow","text":"The MovingWindow method allows you to use any of the above methods (Endpoints, LinearOnLog, or ExpOnLinear) without defining the start and end points of the exponential phase. Instead, you can provide a number of timepoints (a.k.a. window_size, defaults to 10) and it will calculate the growth rate on all consequetive runs of that length and return the maximum growth rate.\n\nBy default, the growth rates on each window are calculated using the Endpoints method. This can be changed by supplying a method keyword argument to MovingWindow. The available options are :Endpoints (default), :LinearOnLog, and :ExpOnLinear.\n\nIt can be called using growth_rate(data, time_col, MovingWindow(window_size, method)) or doubling_time(data, time_col, MovingWindow(window_size, method)).","category":"section"},{"location":"plate_readers/growth_rate/#FiniteDiff","page":"Growth Rate","title":"FiniteDiff","text":"The FiniteDiff method log-transforms the data (removing any points ≤ 0) and then calculates the local gradients. It does this by traveling along the timepoints one-by-one, either calculating the central or one-sided finite difference. It then returns the maximum gradient.\n\nfracln (od(t_i)) - ln (od(t_i-1))t_i - t_i-1 quad textone-sided \nfracln (od(t_i+1)) - ln (od(t_i-1))t_i+1 - t_i-1 quad textcentral\n\nIt can be called using growth_rate(data, time_col, FiniteDiff()) (defaults to central) or any of growth_rate(data, time_col, FiniteDiff(method=:onesided)), or growth_rate(data, time_col, FiniteDiff(method=:central)). You can also call doubling_time with either of the FiniteDiff methods.","category":"section"},{"location":"plate_readers/growth_rate/#Logistic","page":"Growth Rate","title":"Logistic","text":"The Logistic method is a parameteric method that fits a logistic curve to the data and returns b.\n\nfracL1 + exp(-b (t - t_0))\n\nIt can be called using growth_rate(data, time_col, Logistic()) or doubling_time(data, time_col, Logistic()).\n\ntodo: todo\nadd parametric models here too","category":"section"},{"location":"plate_readers/growth_rate/#Regularization","page":"Growth Rate","title":"Regularization","text":"todo: tidi\nmaths of regularization\n\nFor the Regularization method, the data is log scaled (negative points removed) and smoothed using regularization, before being interpolated by a cubic spline. The derivative of the cubic spline is then calculated at all timepoints and the maximum derivative is returned.\n\nIt can be called using growth_rate(data, time_col, Regularization()) or doubling_time(data, time_col, Regularization()).","category":"section"},{"location":"plate_readers/growth_rate/#Implementation-Details","page":"Growth Rate","title":"Implementation Details","text":"If you want to implement a new growth rate method to be included in ESM, you need to:\n\nOpen a pull request with the following code changes\nDefine a new struct for your method type in src/methods.jl\nThe type of that struct is a subtype of AbstractGrowthRateMethod\nDefine a new method dispatch growth_rate(data, time_col, ::NameOfNewMethodType)\nDocument that method in the growth rate documentation (this page)\n\nIf you are unsure how to do any of these steps, feel free to open an issue on GitHub asking for a new growth rate method and explaining how the method should work.","category":"section"},{"location":"plate_readers/growth_rate/#ESM.growth_rate","page":"Growth Rate","title":"ESM.growth_rate","text":"growth_rate(df, time_col, method::AbstractGrowthRateMethod)\n\nCalculates the growth rate of a given dataframe. Returns in min^-1 using base e.\n\nArguments:\n\ndf::DataFrame: DataFrame containing the data.\ntime_col::DataFrame: DataFrame containing the times.\nmethod::AbstractGrowthRateMethod: Method to use for calculating growth rate.\n\n\n\n\n\n","category":"function"},{"location":"plate_readers/growth_rate/#ESM.doubling_time","page":"Growth Rate","title":"ESM.doubling_time","text":"doubling_time(df, time_col, method::AbstractGrowthRateMethod; kwargs...)\n\nCalculates the doubling time of a given DataFrame. Returns result in minutes.\n\nArguments:\n\ndf::DataFrame: DataFrame containing the data.\ntime_col::DataFrame: DataFrame containing the times.\nmethod::AbstractGrowthRateMethod: Method to use for calculating growth rate.\nkwargs...: Additional keyword arguments to pass to the growth rate method.\n\n\n\n\n\n","category":"function"},{"location":"cli/#Command-Line-Interface","page":"Command Line Interface","title":"Command Line Interface","text":"The command line interface allows you to interact with, create and edit .esm files. The functions are documented here and can also be seen by using esm -h. The help for each function can be seen by using esm summarise -h or esm template -h for example.","category":"section"},{"location":"cli/#summarise","page":"Command Line Interface","title":"summarise","text":"A typcial working begins with esm summarise, which lets you view your raw data. This can be helpful for decisions such as detecting contamination in blank wells, gating, etc.","category":"section"},{"location":"cli/#template","page":"Command Line Interface","title":"template","text":"To convert and collect your data into a .esm file, you first want to create an Excel file that describes your data and how it should be imported, processed and viewed. A template Excel file can be loaded using the esm template ... function. To see how the Excel file should be filled out, check out Getting Started with ESM or Excel Interface.","category":"section"},{"location":"cli/#translate","page":"Command Line Interface","title":"translate","text":"Once the template has been filled out and completed, it can be translated into a .esm file using the esm translate ... function.","category":"section"},{"location":"cli/#views","page":"Command Line Interface","title":"views","text":"To create the views from a .esm file, you can use the esm views ... function. This saves the views as .csv files or plots relevant figures.","category":"section"},{"location":"cli/#ESM.summarise-cli","page":"Command Line Interface","title":"ESM.summarise","text":"esm summarise\n\nSummarise a data file (.esm, plate reader, .fcs, etc.).\n\nOptions\n\n-f, --file=<String>: The data file to be summarised.\n-t, --type=<String>: The type of data file. Options are \"auto\" (default), \"esm\",   \"spectramax\", \"biotek\", \"generic\", \"fcs\". If \"auto\" is selected, the type will be   inferred from the file extension (or raise an error if not possible).\n\nFlags\n\n-p, --plot: Produce plots of the data. Only available for some types.\n\n\n\n\n\n","category":"function"},{"location":"cli/#ESM.template-cli","page":"Command Line Interface","title":"ESM.template","text":"esm template\n\nProduce a template excel file for data entry into the ESM.\n\nOptions\n\n-o, --output-path=<String>: The path to create the template in. Defaults to ESM.xlsx in   the current directory.\n\n\n\n\n\n","category":"function"},{"location":"cli/#ESM.translate-cli","page":"Command Line Interface","title":"ESM.translate","text":"esm translate\n\nTranslates the completed .xlsx template file to a .esm file.\n\nOptions\n\n-e, --excel=<String>: The .xlsx template file to be read.\n-t, --target=<String>: The name of the output .esm file.\n\n\n\n\n\n","category":"function"},{"location":"cli/#ESM.views-cli","page":"Command Line Interface","title":"ESM.views","text":"esm views\n\nProduce and save the views from a .esm file.\n\nOptions\n\n-e, --esm-file=<String>: The .esm file to be read.\n-v, --view=<String>: The view to be produced. All views if not specified.\n-o, --output-dir=<String>: The directory to save the output(s) to. Defaults to the   current directory.\n\n\n\n\n\n","category":"function"},{"location":"plate_readers/#plate_reader","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"plate_readers/#Data-Formats","page":"Introduction","title":"Data Formats","text":"ESM currently supports importing data from the following plate readers:\n\nSpectraMax\nBioTek\nTecan\nGeneric tabular data (format specified in Compatibility)\n\nThis list is being continualy expanded. If you have a plate reader machine that is not in this list, and are interested in helping us support it within ESM, please open an issue on GitHub, and upload a data file from that machine.\n\nFor more details on the plate reader formats we support, how they have been verified, and how new methods can be added, please see the Compatibility page.","category":"section"},{"location":"plate_readers/#Methods","page":"Introduction","title":"Methods","text":"ESM provides a variety of methods for handling some common summary statistics. These summary statistics are:\n\nGrowth Rate (or doubling time)\nPer cell fluorescence\nCalibration","category":"section"},{"location":"plate_readers/#Summarise","page":"Introduction","title":"Summarise","text":"If you wish to get an overview of some plate reader data, without needing to set up a full .esm file, you can use summarise.\n\nusing ESM\nsummarise(\"path/to/spectramax-data.csv\", SpectraMax())\n# or if you want plots as well\nsummarise(\"path/to/spectramax-data.csv\", SpectraMax(); plot=true)\n\nesm summarise --file path/to/spectramax-data.csv --type spectramax\nesm summarise --file path/to/spectramax-data.csv --type spectramax --plot\n\nIf plots are included (either through the flag on the CLI or the keyword arguement through the Julia package), then a PDF file at path/to/spectramax-data.csv.pdf will be created with plots of all wells, and temperature, over time, for all channels.","category":"section"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Base.read-Tuple{AbstractString, SpectraMax}","page":"API","title":"Base.read","text":"read(file::AbstractString, ::AbstractPlateReader; channels)\n\nRead data from plate reader file file of assuming the format of AbstractPlateReader.\n\nArguments:\n\nfile::AbstractString: File to read from.\n::AbstractPlateReader: Plate reader type.\nchannels: Vector of channels (as strings) to be read in. Defaults to nothing (all   channels).\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.summary-Tuple{AbstractString, ESMData}","page":"API","title":"Base.summary","text":"summary(file, ptype::AbstractESMDataType; plot=false)\n\nSummarise a data file (.esm, plate reader, .fcs, etc.).\n\nArguments\n\nfile::AbstractString: The data file to be summarised.\nptype::AbstractESMDataType: The type of data file.\nplot::Bool=false: Produce plots of the data. Defaults to false.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.at_od-Tuple{Any, Any, Any}","page":"API","title":"ESM.at_od","text":"at_od(od_df,target_df,target_od)\n\nA function to return a set of values from a different dataframe based on another. In theory this can be used for many types of data, but this adds the functionality to target a specific OD and return the values from another dataframe at that index.\n\nArguments:\n\nod_df::DataFrame: The DataFrame you are getting the indexes from.\ntarget_df::DataFrame: The DataFrame you want to get the values from.\ntarget_od::Number: The value at which you are limiting the data to\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.at_time-Tuple{DataFrames.DataFrame, DataFrames.DataFrame, Any}","page":"API","title":"ESM.at_time","text":"at_time(df, time_col, time_point)\n\nReturns values at a specific time point. If no value at specific timepoint, return the last recording before the timepoint. If timepoint < minimum(timecol), return nothing.\n\nArguments:\n\ndf::DataFrame: DataFrame on which to work.\ntime_col::DataFrame: Time values in a DataFrame.\ntime_point::Float64: Time point in mins at which to report the measurement.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.between_times-Tuple{DataFrames.DataFrame, DataFrames.DataFrame}","page":"API","title":"ESM.between_times","text":"between_times(df,time_col;mint=-Inf,maxt=Inf)\n\nReturns the DataFrame between two timepoints.\n\nArguments:\n\ndf::DataFrame: DataFrame to work on.\ntime_col::DataFrame: DataFrame of time values.\nmint::Float64=-Inf: Minimum time in mins.\nmaxt::Float64=Inf: Max time in mins.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.calibrate-Tuple{Any, Any, TimeseriesBlank}","page":"API","title":"ESM.calibrate","text":"calibrate(data, time_col, method::AbstractCalibrationMethod)\n\nCalibrate data, for example, to remove background OD signal.\n\nArguments:\n\ndata::DataFrame: DataFrame containing the data to be calibrated.\ntime_col::Union{DataFrame, Nothing}: Time column associated with the data.\nmethod::AbstractCalibrationMethod: Method to use for calibration.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.comonicon_install-Tuple{}","page":"API","title":"ESM.comonicon_install","text":"comonicon_install(;kwargs...)\n\nInstall the CLI manually. This will use the default configuration in Comonicon.toml, if it exists. For more detailed reference, please refer to Comonicon documentation.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.comonicon_install_path-Tuple{}","page":"API","title":"ESM.comonicon_install_path","text":"comonicon_install_path(;[yes=false])\n\nInstall the PATH and FPATH to your shell configuration file. You can use comonicon_install_path(;yes=true) to skip interactive prompt. For more detailed reference, please refer to Comonicon documentation.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.df2time-Tuple{DataFrames.DataFrame}","page":"API","title":"ESM.df2time","text":"df2time(time_col)\n\nConverts a time column in a DataFrame with String elements to time in seconds.\n\nArguments:\n\ntime_col::DataFrame: DataFrame with time values.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.doubling_time-Tuple","page":"API","title":"ESM.doubling_time","text":"doubling_time(df, time_col, method::AbstractGrowthRateMethod; kwargs...)\n\nCalculates the doubling time of a given DataFrame. Returns result in minutes.\n\nArguments:\n\ndf::DataFrame: DataFrame containing the data.\ntime_col::DataFrame: DataFrame containing the times.\nmethod::AbstractGrowthRateMethod: Method to use for calculating growth rate.\nkwargs...: Additional keyword arguments to pass to the growth rate method.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.event_count-Tuple{Any}","page":"API","title":"ESM.event_count","text":"event_count(data)\n\nCount the number of events in the flow cytometry data.\n\nArguments:\n\ndata::Dict: Dict returned by to_rfi.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.expand_group-Tuple{AbstractString}","page":"API","title":"ESM.expand_group","text":"expand_group(group::AbstractString)\n\nExpand a condensed group name into the sample IDs it contains. For example, if the group is \"plate0[1,2][a:c]2\", it will return all sample IDs from plate 1 to 2 and wells a2, b2, and c2.\n\nArguments:\n\ngroup::AbstractString: The group name to expand.\n\nReturns:\n\nVector{String}: A vector of sample IDs contained in the group.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.expand_groups-Tuple{AbstractString}","page":"API","title":"ESM.expand_groups","text":"expand_groups(groups::AbstractString)\n\nIteratively call expand_group on a comma-separated list of group names.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.extract_flow-Tuple{Any, Any}","page":"API","title":"ESM.extract_flow","text":"extract_flow(fcs,chan)\n\nExtract the metadata from a FCSFiles.FlowSample.\n\nArguments:\n\nfcs: The parsed FCS file.\nchan::String: The channel being read from.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.filter_col-Tuple{Any, Any}","page":"API","title":"ESM.filter_col","text":"filter_col(df, reg_l)\n\nFilters a df by a set of columns or parts of columns given in regl. regl is joined to form regex using |.\n\nArguments:\n\ndf::DataFrame: DataFrame to filter.\nreg_l::Vector{String}: Vector of strings to filter by.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.filter_row-Tuple{Any, Any}","page":"API","title":"ESM.filter_row","text":"filter_row(es,group)\n\nFilter the original es.samples dataframe by a specific group defined in the esm.\n\nArguments:\n\nes::esm_zones: esm zones data type.\ngroup::Union{String,Vector}: what group/groups to filter by.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.find_group-Tuple{Any, Any}","page":"API","title":"ESM.find_group","text":"find_group(es,grn)\n\nFinds a specific group from the original es.groups dataframe. Returns the sample names.\n\nArguments:\n\nes::esm_zones: The data set to search.\ngrn::String: A string of a group name which can be used to filter the original   dataframe.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.fit_ellipse-Tuple{Any, Any}","page":"API","title":"ESM.fit_ellipse","text":"fit_ellipse(x, y) → a, b, θ, x₀, y₀, p\n\nFit an ellipse into the 2D data defined by (x, y) using ordinary least squares.\n\nReturn: semi-major axis length, semi-minor axis length, ellipse rotation, center coordinates and a parameter container for quadratic form of ellipse. The first five parameters represent the parametric form of an ellipse, which may have an arbitrary rotation and translation w.r.t. the origin:\n\nx(t) = cos(θ)*a*cos(t) - sin(θ)*b*sin(t) + x₀\ny(t) = sin(θ)*a*cos(t) + cos(θ)*b*sin(t) + y₀\nt ∈ [0, 2π)\n\nUse ellipse_from_parametric(a, b, θ, x₀, y₀) → x, y to construct points along the ellipse. Notice that always two possible ellipses can fit the data, one with a, b, θ and one with b, a, θ-π/2.\n\nThe quadratic form of the ellipse is created using p, and is given by the form (x^2, x*y, y^2, x, y) ⋅ p = 1.\n\nCode modified from: https://www.matecdev.com/posts/julia-least-squares-qr.html using a lot of stuff from: https://en.wikipedia.org/wiki/Ellipse#General_ellipse\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.form_df-Tuple{Any}","page":"API","title":"ESM.form_df","text":"form_df(df)\n\nCreates the data frame from the dataframe it is passed. This is to turn the es.samples.values arrays into dfs.\n\nArguments:\n\ndf::DataFrame: A dataframe of es.samples to parse.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.gate","page":"API","title":"ESM.gate","text":"gate(data, method::AbstractGatingMethod)\n\nFilter data to only include events within the gate defined by method.\n\nArguments:\n\ndata::Dict: Dict returned by to_rfi.\nmethod::AbstractGatingMethod: The method and settings to use for gating.\n\n\n\n\n\n","category":"function"},{"location":"api/#ESM.gated_proportion-Tuple{Any, ESM.AbstractGatingMethod}","page":"API","title":"ESM.gated_proportion","text":"gated_proportion(data, gate)\ngated_proportion(data_before, data_after)\n\nCalculate the proportion of events remaining after gating.\n\nArguments:\n\ndata::Dict: Dict returned by to_rfi.\ngate::AbstractGatingMethod: A gating method to report on.\ndata_before::Dict: Dict returned by to_rfi before gating.\ndata_after::Dict: Dict returned by to_rfi after gating.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.growth_rate-Tuple{Any, Any, Endpoints}","page":"API","title":"ESM.growth_rate","text":"growth_rate(df, time_col, method::AbstractGrowthRateMethod)\n\nCalculates the growth rate of a given dataframe. Returns in min^-1 using base e.\n\nArguments:\n\ndf::DataFrame: DataFrame containing the data.\ntime_col::DataFrame: DataFrame containing the times.\nmethod::AbstractGrowthRateMethod: Method to use for calculating growth rate.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.index_between_vals-Tuple{DataFrames.DataFrame}","page":"API","title":"ESM.index_between_vals","text":"index_between_vals(df; minv=-Inf, maxv=Inf)\n\nReturns the indexes between two points so that these can be later isolated. This is in dict form to allow for individual points to be separated out. Both ends are inclusive.\n\nIf minv is larger than all values in the column, or maxv smaller, will return     (nothing,nothing).\n\nArguments:\n\ndf::DataFrame: DataFrame to work on.\nminv::Float64=-Inf: Minimum value.\nmaxv::Float64=Inf: Maximum value.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.produce_views-Tuple{Any, Any}","page":"API","title":"ESM.produce_views","text":"produce_views(es, trans_meta_map;to_out=[])\n\nProduces the subset of views specified in to_out or all views if unspecified.\n\nArguments:\n\nes::esm_zones: The esm_zones object\ntrans_meta_map::Dict: A dictionary mapping transformations to their names.\nto_out::Vector{String}: A list of all the views to be produced.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.read_data-Tuple{AbstractString}","page":"API","title":"ESM.read_data","text":"read_data(file::AbstractString)\n\nRead the data from path file into the correct structure.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.read_esm-Tuple{AbstractString}","page":"API","title":"ESM.read_esm","text":"read_esm(file::AbstractString)\n\nParse an esm file found at file into an esm_zones object.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.read_flow-NTuple{5, Any}","page":"API","title":"ESM.read_flow","text":"read_flow(samples, sample_dict,channels,broad_g,channel_map)\n\nRead the flow cytometry data from a file.\n\nArguments:\n\nsamples::DataFrame: DataFrame of samples to read from.\nsample_dict::Dict: Output sample Dict.\nchannels::Vector: Channels to read.\nbroad_g::Vector: The physical group that this is part of.\nchannel_map::Dict: The names to replace the old channel names with.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.read_multipr_file-NTuple{4, Any}","page":"API","title":"ESM.read_multipr_file","text":"read_multipr_file(file,ptype,channels,channel_map)\n\nFunction for reading files containing multiple reads from multple channels from a single CSV     file. Returns a Dictionary of DataFrames with keys being the channels.\n\nArguments:\n\nfile::String: File to read from.\nptype::String: The plate reader type being used.\nchannels::Vector: Channels to be read in.\nchannel_map: The new names for the channels.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.read_pr-NTuple{5, Any}","page":"API","title":"ESM.read_pr","text":"read_pr(samples,sample_dict,channels,broad_g,channel_map)\n\nReads plate reader data.\n\nArguments:\n\nsamples::DataFrame: Dataframe of samples to be read into sample_dict.\nsample_dict::Dict: A dictionary of the samples.\nchannels::Vector: Channels to use.\nbroad_g::Vector: The larger plate that this belongs to.\nchannel_map::Dict: What to rename the channel to.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.remove_subcols-Tuple{Any, Any}","page":"API","title":"ESM.remove_subcols","text":"remove_subcols(df, sub)\n\nGets rid of certain sub col ids in the col names.\n\ne.g. \n\nremove flo\na1.flo -> a1\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.sexp_to_nested_list-Tuple{Any, Any, Any}","page":"API","title":"ESM.sexp_to_nested_list","text":"sexp_to_nested_list(sexp,es,trans_meta_map)\n\nRecursively converts the parsed equations to julia code and produces the correct dataframes     over which to operate. This also calls any unprocessed transformations.\n\nArguments:\n\nsexp: Expression or part of expression to be decomposed.\nes: The esm_zones data type that contains the data.\ntransmetamap: The transformation map of the parsed transformations.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.summarise","page":"API","title":"ESM.summarise","text":"esm summarise\n\nSummarise a data file (.esm, plate reader, .fcs, etc.).\n\nOptions\n\n-f, --file=<String>: The data file to be summarised.\n-t, --type=<String>: The type of data file. Options are \"auto\" (default), \"esm\",   \"spectramax\", \"biotek\", \"generic\", \"fcs\". If \"auto\" is selected, the type will be   inferred from the file extension (or raise an error if not possible).\n\nFlags\n\n-p, --plot: Produce plots of the data. Only available for some types.\n\n\n\n\n\n","category":"function"},{"location":"api/#ESM.template","page":"API","title":"ESM.template","text":"esm template\n\nProduce a template excel file for data entry into the ESM.\n\nOptions\n\n-o, --output-path=<String>: The path to create the template in. Defaults to ESM.xlsx in   the current directory.\n\n\n\n\n\n","category":"function"},{"location":"api/#ESM.to_rfi-Tuple{Any, Any}","page":"API","title":"ESM.to_rfi","text":"to_rfi(sample_name;chans=[])\n\nCalculates relative fluorescence of given sample.\n\nArguments:\n\nsample_name::String: channel to use.\nchans::Vector: vector of channels to keep.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.translate","page":"API","title":"ESM.translate","text":"esm translate\n\nTranslates the completed .xlsx template file to a .esm file.\n\nOptions\n\n-e, --excel=<String>: The .xlsx template file to be read.\n-t, --target=<String>: The name of the output .esm file.\n\n\n\n\n\n","category":"function"},{"location":"api/#ESM.view_to_csv-Tuple{Any, Any}","page":"API","title":"ESM.view_to_csv","text":"view_to_csv(es,trans_meta_map;out_dir,to_out)\n\nProduces views and writes them to CSV files.\n\nArguments:\n\nes::esm_zones: The original esm struct\ntrans_meta_map::Dict: The transformations that have been parsed at the top level.\noutdir::String: The specified output dir - defaults to nothing.\nto_out::Vector{String}: The views to be processed.\n\n\n\n\n\n","category":"method"},{"location":"api/#ESM.views","page":"API","title":"ESM.views","text":"esm views\n\nProduce and save the views from a .esm file.\n\nOptions\n\n-e, --esm-file=<String>: The .esm file to be read.\n-v, --view=<String>: The view to be produced. All views if not specified.\n-o, --output-dir=<String>: The directory to save the output(s) to. Defaults to the   current directory.\n\n\n\n\n\n","category":"function"},{"location":"api/#ESM.write_esm-Tuple{Any, AbstractString}","page":"API","title":"ESM.write_esm","text":"write_esm(data, file::AbstractString)\n\nWrite the esm data to the path file.\n\n\n\n\n\n","category":"method"},{"location":"data_format/#Data-Format","page":"Data Format","title":"Data Format","text":"The ESM data format (the format used for .esm files) is a JSON format, with its highest level storing 4 key-value pairs. The keys are \"samples\", \"groups\", \"transformations\", and \"views\", with their values defined as outlined below.","category":"section"},{"location":"data_format/#Samples","page":"Data Format","title":"Samples","text":"Samples stores key-value pairs, with keys as the sample names. Each samples stores its own variables (in key-value pairs), with:\n\na variable called \"values\" that stores the channel data as key-value pairs (with each channel storing an ordered list),\na \"type\" variable that indicates whether the data is a \"timeseries\" (like plate reader data) or \"population\" (like flow cytometry data),\nand a \"meta\" variable to store any other associated data in key-value pairs, such as amplifier settings.\n\ntodo: Todo\nRename meta to metadata\n\n{\n    \"samples\":{\n        \"plate_01_time\":{\n            \"values\":{\n                \"OD\":[\n                    \"00:08:38\",\n                    \"18:38:38\"\n                ],\n                \"flo\":[\n                    \"00:09:04\",\n                    \"18:39:04\"\n                ]\n            },\n            \"type\":\"timeseries\",\n            \"meta\":{}\n        },\n        \"plate_01_temperature\":{\n            \"values\":{\n                \"OD\":[\n                37.0,\n                37.0\n            ]\n            },\n            \"type\":\"timeseries\",\n            \"meta\":{}\n        },\n        \"plate_01_a1\":{\n            \"values\":{\n                \"OD\":[\n                    0.165,\n                    0.916\n                ],\n                \"flo\":[\n                    21,\n                    371\n                ]\n            },\n            \"type\":\"timeseries\",\n            \"meta\":{}\n        },\n        \"plate_01_h12\":{\n            \"values\":{\n                \"OD\":[\n                    0.16,\n                    0.148\n                ],\n                \"flo\":[\n                    9,\n                    7\n                ]\n            },\n            \"type\":\"timeseries\",\n            \"meta\":{}\n        },\n        \"plate_02_a1\":{\n            \"values\":{\n                \"FL1_H\":[\n                    9.057978,\n                    537.61176,\n                    6.152654,\n                    259.45526\n                ],\n                \"SSC_H\":[\n                    280.0,\n                    735.0,\n                    128.0,\n                    1023.0\n                ]\n            },\n            \"type\":\"population\",\n            \"meta\":{\n                \"FL1_H\":{\n                    \"range\":\"1024\",\n                    \"ex_pow\":null,\n                    \"filter\":null,\n                    \"det_volt\":null,\n                    \"amp_type\":\"0,0\",\n                    \"ex_wav\":null,\n                    \"amp_gain\":\"4\",\n                    \"name_s\":null,\n                    \"name\":\"FL1-H\",\n                    \"det_type\":null,\n                    \"perc_em\":null\n                },\n                \"SSC_H\":{\n                    \"range\":\"1024\",\n                    \"ex_pow\":null,\n                    \"filter\":null,\n                    \"det_volt\":null,\n                    \"amp_type\":\"2,0.01\",\n                    \"ex_wav\":null,\n                    \"amp_gain\":null,\n                    \"name_s\":\"SSC-H\",\n                    \"name\":\"SSC-H\",\n                    \"det_type\":null,\n                    \"perc_em\":null\n                }\n            }\n        }\n    },\n}","category":"section"},{"location":"data_format/#Groups","page":"Data Format","title":"Groups","text":"Under groups, we have key-value pairs (the name of the group is the key) with:\n\na variable called \"type\" that defines whether the group is a physical group (plates), or an experimental group (like blanks or controls),\na variable called \"sample_IDs\" that defines which samples are included in the group as an ordered list,\nand a variable called \"metadata\" that may include any additional information about the group, such as whether the group was automatically defined, as is done with the \"plate\" groups.\n\n{\n   \"groups\":{\n        \"first_group\":{\n            \"type\":\"experimental\",\n            \"sample_IDs\":[\n                \"plate_01_A1\",\n                \"plate_01_A5\",\n                \"plate_01_A9\"\n            ],\n            \"metadata\":{}\n        },\n        \"second_group\":{\n            \"type\":\"experimental\",\n            \"sample_IDs\":[\n                \"plate_01_A3\",\n                \"plate_01_A8\",\n                \"plate_01_A7\"\n            ],\n            \"metadata\":{}\n        },\n        \"third_group\":{\n            \"type\":\"experimental\",\n            \"sample_IDs\":[\n                \"plate_01_A1\",\n                \"plate_01_A2\",\n                \"plate_01_A3\"\n            ],\n            \"metadata\":{}\n        },\n        \"plate_01\":{\n            \"type\":\"physical\",\n            \"sample_IDs\":[\n                \"plate_01_time\",\n                \"plate_01_t° read 1:700\",\n                \"plate_01_a1\",\n                \"plate_01_h12\"\n            ],\n            \"metadata\":{\n                \"autodefined\":\"true\"\n            }\n        },\n        \"plate_02\":{\n            \"type\":\"physical\",\n            \"sample_IDs\":[\n                \"plate_02_a1\"\n            ],\n            \"metadata\":{\n                \"autodefined\":\"true\"\n            }\n        }\n    },\n}","category":"section"},{"location":"data_format/#Transformations","page":"Data Format","title":"Transformations","text":"Under transformations, we have key-value pairs (the name of the transformation is the key) with a variable called \"equation\" that stores the transformation as a string.\n\n{\n    \"transformations\":{\n        \"flow_cyt\":{\n            \"equation\":\"process_fcs(\\\"plate_02\\\",[\\\"FSC_H\\\",\\\"SSC_H\\\"],[\\\"FL1_H\\\"])\"\n        },\n        \"flow_sub\":{\n            \"equation\":\"hcat(first_group.flo,second_group.flo).-mean(third_group.flo)\"\n        },\n        \"od_sub\":{\n            \"equation\":\"hcat(first_group.OD,second_group.OD).-mean(third_group.OD)\"\n        }\n    },\n}","category":"section"},{"location":"data_format/#Views","page":"Data Format","title":"Views","text":"Under views, we have key-value pairs (name of the view is the key) with a variable called \"data\" that represents an ordered list of groups, transformations, wells, etc. to be included in the view.\n\n{\n    \"views\":{\n        \"flow_cy\":{\n            \"data\":[\n            \"flow_cyt\"\n        ]\n        },\n        \"group1\":{\n            \"data\":[\n            \"first_group\"\n        ]\n        },\n        \"group2\":{\n            \"data\":[\n            \"second_group\"\n        ]\n        },\n        \"group3\":{\n            \"data\":[\n            \"third_group\"\n        ]\n        },\n        \"sample\":{\n            \"data\":[\n            \"plate_01_time.flo\"\n        ]\n        },\n        \"flowsub\":{\n            \"data\":[\n            \"flow_sub\"\n        ]\n        },\n        \"odsub\":{\n            \"data\":[\n            \"od_sub\"\n        ]\n        },\n        \"mega\":{\n            \"data\":[\n            \"first_group\",\n            \"second_group\"\n        ]\n        }\n    }\n}","category":"section"},{"location":"flow_cytometers/#flow_cytometry","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"flow_cytometers/#Data-Formats","page":"Introduction","title":"Data Formats","text":"ESM currently supports importing data from flow cytometry .fcs files. Specifically, it supports FCS versions XXXX.\n\ntodo: todo\nfcs versions compatibility\n\nIf you require support for a different FCS version, please open an issue on GitHub, and let us know what version you require.","category":"section"},{"location":"flow_cytometers/#Methods","page":"Introduction","title":"Methods","text":"ESM provides a variety of methods for gating flow cytometry data. These are split into two categories: Automatic Gating and Manual Gating.\n\nAutomatic Gating has a collection of methods that will automatically gate the data, requiring at most specifying the channels to gate on.\n\nManual Gating is designed to allow you to perform gating in separate software, and then include those gates in ESM.","category":"section"},{"location":"flow_cytometers/#Summarise","page":"Introduction","title":"Summarise","text":"If you wish to get an overview of some flow cytometry data, without needing to set up a full .esm file, you can use summarise.\n\nusing ESM\nsummarise(\"path/to/data.fcs\")\n# or if you want plots as well\nsummarise(\"path/to/data.fcs\"; plot=true)\n\nesm summarise --file path/to/data.fcs\n# or if you want plots as well\nesm summarise --file path/to/data.fcs --plot\n\nIf plots are included (either through the flag on the CLI or the keyword arguement through the Julia package), then a PDF file at path/to/data.fcs.pdf will be created with histograms of each channel, and 2D heatmaps of all pairs of channels.","category":"section"},{"location":"flow_cytometers/manual_gating/#Manual-Gating","page":"Manual Gating","title":"Manual Gating","text":"There are a variety of types of gates that can be applied to flow cytometry data. Each method uses the gate(data, Method()) function signature which will return the subset of events in data that satisfy that gate. These can be used either in the Julia ESM package diectly, or in the transformations in the Excel template.\n\ntip: Flow cytometry samples and groups\nWhen using ESM transformations, samples and groups are automatically converted to relative fluoresence intensity. This allows you to use gate on any flow sample or group of flow samples.","category":"section"},{"location":"flow_cytometers/manual_gating/#HighLowGate","page":"Manual Gating","title":"HighLowGate","text":"The HighLowGate removes any events that are below lb in channel or above ub in channel. If one of the bounds is not specified, it will not be used to remove any data.\n\nIt can be called using gate(data, HighLowGate(channel, lb, ub)).\n\nnote: Upper and Lower Bounds\nLower bounds are always inclusive (lb≤data[channel]) while upper bounds are always exclusive (data[channel]<ub).","category":"section"},{"location":"flow_cytometers/manual_gating/#RectangleGate","page":"Manual Gating","title":"RectangleGate","text":"The RectangleGate is equivalent to applying two HighLowGates. It returns all data where:\n\nlb1  datachannel1  ub1 \ntextand \nlb2  datachannel2  ub2 \n\nAs with the HighLowGate, any of the upper and lower bounds can be left out to avoid gating on that bound.\n\nIt can be called using gate(data, RectangleGate(channel1, channel2, lb1, ub1, lb2, ub2)).","category":"section"},{"location":"flow_cytometers/manual_gating/#QuadrantGate","page":"Manual Gating","title":"QuadrantGate","text":"The QuadrantGate is defined by a single point, a pair of values and channels. The values split all events into 4 quadrants, (high channel 1 and high channel 2, high channel 1 and low channel 2, low channel 1 and low channel 2, low channel 1 and high channel 2). You then need to specify a quadrant you want to return, numbered 1 through 4 in that order.\n\ntip: Remembering the quadrant order\nIf you were to plot the data with channel1 on the x-axis and channel2 on the y-axis, then quadrant 1 is in the top right corner, and the remaining quadrants are given by travelling clockwise.\n\nIt can be called using gate(data, QuadrantGate(channel1, channel2, channel1value, channel2value, quadrant)).","category":"section"},{"location":"flow_cytometers/manual_gating/#PolygonGate","page":"Manual Gating","title":"PolygonGate","text":"The PolygonGate can be used to create arbitrary polygons, gating to remove any data that doesn't fit inside the polygon. A PolygonGate can be created from a series of x-y coordinates describing the vertices of the polygon.\n\nIt can be called using gate(data, PolygonGate(channel1, channel2, points)).","category":"section"},{"location":"flow_cytometers/manual_gating/#EllipseGate","page":"Manual Gating","title":"EllipseGate","text":"The EllipseGate can be used to remove data that falls outside of a predefined ellipse. An EllipseGate can be created from 5 points that fall on the ellipse, or 3-5 points that fall on the ellipse and the ellipse's center.\n\nIt can be called using gate(data, EllipseGate(channel1, channel2, points)) or gate(data, EllipseGate(channel1, channel2, center, points)).","category":"section"},{"location":"flow_cytometers/manual_gating/#Logical-Operations-on-Gates","page":"Manual Gating","title":"Logical Operations on Gates","text":"You can also perform logical operations on gates. The logical operations are and, or, and not. They can be used either through operators (HighLowGate(channel=\"FL1_A\", lb=500.0, ub=2000.0) & QuadrantGate(channel1=\"SSC_A\", ...)) or through the and function (and(HighLowGate(channel=\"FL1_A\", lb=500.0, ub=2000.0), QuadrantGate(channel1=\"SSC_A\", ...))). This will return an AndGate (| and or returns an OrGate, and ! and not return a NotGate) which can then be gated on (gate(data, HighLowGate(...) & QuadrantGate(...))).","category":"section"},{"location":"flow_cytometers/manual_gating/#Implementation-Details","page":"Manual Gating","title":"Implementation Details","text":"If you want to implement a new manual gate to be included in ESM, you need to:\n\nOpen a pull request with the following code changes\nDefine a new struct for your method type in src/methods.jl\nThe type of that struct is a subtype of AbstractManualGate\nDefine a new method dispatch gate(data, ::NameOfNewMethodType)\nDocument that method in the manual gating documentation (this page)\n\nnote: Note\nGates can only return a single group that \"passes\" the gate. For example, it is not possible to have a single QuadrantGate that separates the data into all four quadrants. This is so that it plays nicely with the ESM transformations. If you need to gate into all four quadrants, you should define four QuadrantGates, each with different values of the quadrant parameter.\n\nIf you are unsure how to do any of these steps, feel free to open an issue on GitHub asking for a new manual gate and explaining how the gate should work.","category":"section"},{"location":"flow_cytometers/manual_gating/#ESM.gate-flow_cytometers-manual_gating","page":"Manual Gating","title":"ESM.gate","text":"gate(data, method::AbstractGatingMethod)\n\nFilter data to only include events within the gate defined by method.\n\nArguments:\n\ndata::Dict: Dict returned by to_rfi.\nmethod::AbstractGatingMethod: The method and settings to use for gating.\n\n\n\n\n\n","category":"function"},{"location":"plate_readers/calibration/#Calibration","page":"Calibration","title":"Calibration","text":"There are a few different methods for calibrating plate reader OD and fluorescence data. Each method uses the calibrate(data, time_col, Method()) function signature. These can be used either in the Julia ESM package diectly, or in the transformations in the Excel template.","category":"section"},{"location":"plate_readers/calibration/#TimeseriesBlank","page":"Calibration","title":"TimeseriesBlank","text":"The TimeseriesBlank method averages across the blank wells, to get a single blank timeseries (assuming all the blanks were measured at the same timepoints). It then subtracts this from the data, timepoint by timepoint. So the first timepoint is calibrated by the average of all the blank wells at the first timepoint, the second is calibrated at the second timepoint and so on.\n\nIt can be called using calibrate(data, time_col, TimeseriesBlank(blanks, blank_time_col)).","category":"section"},{"location":"plate_readers/calibration/#SmoothedTimeseriesBlank","page":"Calibration","title":"SmoothedTimeseriesBlank","text":"The SmoothedTimeseriesBlank method averages across the blank wells, and then fits a straight line through the blank data (equivalent to fitting through all the blank wells without averaging). It then subtracts this line of best fit from each well in the data.\n\nIt can be called using calibrate(data, time_col, SmoothedTimeseriesBlank(blanks, blank_time_col)).","category":"section"},{"location":"plate_readers/calibration/#MeanBlank","page":"Calibration","title":"MeanBlank","text":"The MeanBlank method averages both over wells and over time. This gives a single value to calibrate the data against which is subtracted from the data.\n\nIt can be called using calibrate(data, time_col, MeanBlank(blanks)).","category":"section"},{"location":"plate_readers/calibration/#MinBlank","page":"Calibration","title":"MinBlank","text":"The MinBlank method calculates a single calibration value as the minimum of all wells across all timepoints. It then subtracts this value form the data.\n\nIt can be called using calibrate(data, time_col, MinBlank(blanks)).","category":"section"},{"location":"plate_readers/calibration/#MinData","page":"Calibration","title":"MinData","text":"The MinData method doesn't require blanks. It calculates a single calibration value for each well, as the minimum of each well. It then subtracts these values from each well, so that the data for each well contains one zero (where the minimum was previously), and no negative points.\n\nIt can be called using calibrate(data, time_col, MinData()).","category":"section"},{"location":"plate_readers/calibration/#StartData","page":"Calibration","title":"StartData","text":"The StartData method doesn't require blanks. It calculates a single calibration value for each well, as the initial value of each well. It then subtracts these values from each well, so that the data begins at zero for all wells.\n\nIt can be called using calibrate(data, time_col, StartData()).","category":"section"},{"location":"plate_readers/calibration/#Implementation-Details","page":"Calibration","title":"Implementation Details","text":"If you want to implement a new calibration method to be included in ESM, you need to:\n\nOpen a pull request with the following code changes\nDefine a new struct for your method type in src/methods.jl\nThe type of that struct is a subtype of AbstractCalibrationMethod\nDefine a new method dispatch calibrate(data, time_col, ::NameOfNewMethodType)\nDocument that method in the calibration documentation (this page)\n\nIf you are unsure how to do any of these steps, feel free to open an issue on GitHub asking for a new calibration method and explaining how the method should work.","category":"section"},{"location":"plate_readers/calibration/#ESM.calibrate","page":"Calibration","title":"ESM.calibrate","text":"calibrate(data, time_col, method::AbstractCalibrationMethod)\n\nCalibrate data, for example, to remove background OD signal.\n\nArguments:\n\ndata::DataFrame: DataFrame containing the data to be calibrated.\ntime_col::Union{DataFrame, Nothing}: Time column associated with the data.\nmethod::AbstractCalibrationMethod: Method to use for calibration.\n\n\n\n\n\n","category":"function"},{"location":"flow_cytometers/auto_gating/#Automatic-Gating","page":"Automatic Gating","title":"Automatic Gating","text":"There are a couple of methods for automatically gating flow cytometry data. Each method uses the gate(data, Method()) function signature which will return all the data that passes the automatic gating algorithm. These can be used either in the Julia ESM package diectly, or in the transformations in the Excel template.\n\ntip: Flow cytometry samples and groups\nWhen using ESM transformations, samples and groups are automatically converted to relative fluoresence intensity. This allows you to use gate on any flow sample or group of flow samples.","category":"section"},{"location":"flow_cytometers/auto_gating/#KDE","page":"Automatic Gating","title":"KDE","text":"The KDE method (Kernal Density Estimation) is an automatic gating method based on FlowCal. It generates an 2D histogram in the provided channels. It then smoothes out the densities of this histogram using KernalDensity.jl to remove isolated bins of high density (noise). It then returns some fraction of the data (gate_frac which defaults to 0.65) which is highest in density.\n\ntodo: Animation\nThis is an awkward method to explain, best to create an animation for it.\n\nIt can be called using gate(data, KDE(channels=[\"FSC_A\", \"SSC_A\"], gate_frac=0.65, nbins=1024)) where gate_frac and nbins are optional.","category":"section"},{"location":"flow_cytometers/auto_gating/#Implementation-Details","page":"Automatic Gating","title":"Implementation Details","text":"If you want to implement a new automatic gating method to be included in ESM, you need to:\n\nOpen a pull request with the following code changes\nDefine a new struct for your method type in src/methods.jl\nThe type of that struct is a subtype of AbstractAutoGate\nDefine a new method dispatch gate(data, ::NameOfNewMethodType)\nDocument that method in the automatic gating documentation (this page)\n\nIf you are unsure how to do any of these steps, feel free to open an issue on GitHub asking for a new automatic gating method and explaining how the gate should work.","category":"section"},{"location":"flow_cytometers/auto_gating/#ESM.gate-flow_cytometers-auto_gating","page":"Automatic Gating","title":"ESM.gate","text":"gate(data, method::AbstractGatingMethod)\n\nFilter data to only include events within the gate defined by method.\n\nArguments:\n\ndata::Dict: Dict returned by to_rfi.\nmethod::AbstractGatingMethod: The method and settings to use for gating.\n\n\n\n\n\n","category":"function"},{"location":"excel/#Excel-Interface","page":"Excel Interface","title":"Excel Interface","text":"The Excel interface is accessed through esm template .... It provides an Excel spreadsheet template which can be filled in with information about your data and processing. This is required to create a .esm file from which outputs and views can be produced.\n\nThe Excel template features five sheets to be filled out with relevant information:\n\nSamples\nID\nGroups\nTransformations\nViews\n\nOn this page, we document what is required to be filled out and give examples of how to use the Excel template file.","category":"section"},{"location":"excel/#Samples","page":"Excel Interface","title":"Samples","text":"The first sheet is called \"Samples\" and requires information about where you data is stored and what information should be read from it.\n\nEach row specifies a new file that should be imported into the final .esm file.\n\nThe first few rows control the naming scheme for the samples. By default this will look something like \"plate01a1.600\".\n\nThe first column lets you put in labels for plates. Here, we have labelled them \"1\", \"2\", \"3\", and \"4\". The final names for these plates will be \"plate_01\", \"plate_02\", \"plate_03\", and \"plate_04\".\n\nThe second column controls the well name. For example, if you have flow cytometry data from different wells, stored in different .fcs files, you can label the well that each .fcs file corresponds to.\n\nThe sample names will be stored as plate_0$PLATE NUMBER$_$well name$. That is unless a name is provided in the third column.\n\nThe type defines whether the data is \"plate reader\", \"flow\", or \"qpcr\" and how that file should be imported.\n\nThe data location gives the full filepath to the data.\n\nChannels identifies the specific channels that you would like to save in the ESM file. If left blank, then all will be saved.\n\nFinally, we have the plate reader brand. This identifies the format the data will be in. Available options are: \"spectramax\", \"biotek\", and \"tecan\". Leave it blank for other data types.\n\n(Image: alt text)","category":"section"},{"location":"excel/#ID","page":"Excel Interface","title":"ID","text":"Here you can rename any channels. On the left, provide the channel name, as specified on the previous sheet. On the right, provide the new name for the channel. In this example, rather than using \"plate_01_a5.600\", we would then use \"plate_01_a5.od\".\n\n(Image: alt text)","category":"section"},{"location":"excel/#Groups","page":"Excel Interface","title":"Groups","text":"In this sheet, you can group samples together. For example, you may want to group all of your blank well together to make them easier to refer to.\n\nThere are a few formats for doing this. The simplest is to just write out all the samples in a comma separated list (i.e. \"plate_01_a1, plate_01_a2, plate_01_a3\").\n\nTo make this a bit shorter, you may choose to use the compressed format. In this format, anything specified in [] is expanded.\n\n[b:d] gets expanded to b, c, and d.\n[b:2:f] gets expanded to b, d, and f (step of 2).\n[a,d,e] gets expanded to a, d, and e.\nNumerals are treated likewise.\n\nAll these formats can be mixed together in any combination, so \"plate_0[1,2]_[a:c]1, plate_04_a2\" is treated the same as \"plate_01_a1, plate_01_b1, plate_01_c1, plate_02_a1, plate_02_b1, plate_02_c1, plate_04_a2\".\n\nIn the example:\n\nall wells on the left of a 96 well plate (A through H, column 1) are grouped as \"blank\",\nall wells on the right (A through H, column 12) are groups as \"control\",\nthe remaining wells (A through H, columns 2 through 11) are split into pairs of rows (A and B, C and D, E and F, G and H) into the groups \"ee01\", \"ee02\", \"ee03\", \"ee04\".\n\n(Image: alt text)","category":"section"},{"location":"excel/#Transformations","page":"Excel Interface","title":"Transformations","text":"On the transformations sheet, you can define the post-processing you want to apply to your data. This typically involves calibrations and calculating summary statistics.\n\nIn the left column, you can name your transformation. In the right column, you can provide the code for the transformation you want to run. This can be arbitrary Julia code, but most commonly is just calling one of the ESM methods for Plate Reader, Flow Cytometry, and qPCR data.\n\nIn the example below, we calibrate our groups based on the blank group, then calculate growth rates on each of the calibrated transformations. Finally, the data is collected together (the \"processed\" variable appends the different DataFrames together) and this is normalised by the mean of the controls.\n\n(Image: alt text)","category":"section"},{"location":"excel/#Views","page":"Excel Interface","title":"Views","text":"Finally, the views describe a subset of transformations, groups and samples that you actually want to look at, outside of ESM. This is typically used for your final post-processed data, but can also be useful for debugging (viewing inputs and outputs from a transformation to make sure it is working as intended).\n\nIn the example below, we have a single view named \"growth_rate\", which uses the \"normalized\" transformation we defined previously. Instead of using a transformation, we could have also used a group name, or a sample name.\n\n(Image: alt text)","category":"section"},{"location":"excel/#ESM.expand_group-excel","page":"Excel Interface","title":"ESM.expand_group","text":"expand_group(group::AbstractString)\n\nExpand a condensed group name into the sample IDs it contains. For example, if the group is \"plate0[1,2][a:c]2\", it will return all sample IDs from plate 1 to 2 and wells a2, b2, and c2.\n\nArguments:\n\ngroup::AbstractString: The group name to expand.\n\nReturns:\n\nVector{String}: A vector of sample IDs contained in the group.\n\n\n\n\n\n","category":"function"},{"location":"#ESM-(Experimental-Simple-Model)","page":"Introduction","title":"ESM (Experimental Simple Model)","text":"","category":"section"},{"location":"#ESM.ESM","page":"Introduction","title":"ESM.ESM","text":"Experimental Simple Model (ESM)\n\n(Image: Tests) (Image: codecov) (Image: docs)\n\nWhat is ESM?\n\nESM is a data format and supporting tools to enable accessible and reproducible data processing for engineering biology.\n\nIt allows standardised and reproducible processing of plate reader, flow cytometry, and qPCR data.\n\nHow does it work?\n\nThe ESM data format is composed of a structured JSON file (named the .esm file) containing the raw data (in a standardised format) and the post-processing commands that are run on the data. This means that uploading a .esm file a supplementary data for an article allows anyone to view the raw data and see (and reproduce) exactly how it was processed to derive the results seen in the article.\n\nSince we have all the data in a standardised format, we can (and do) provide a set of methods for processing the data. This includes calibration methods, flow cytometry gating, and calculating summary statistics such as growth rate or per cell fluorescence. While we provide many possible methods for each of these, we also offer sensible, robust, benchmark-verified defaults that should work in the majority of cases.\n\nESM can be used either as a Julia package, or more typically, through its command line interface. If you want to learn how to use ESM, check out the documentation.\n\nContributing\n\nThere are a couple of ways you can contribute towards ESM.\n\nIf you have a method that you would like to see included in ESM, please open a new issue,\nIf you have a plate reader machine that isn't currently supported (see the docs for current compatability), please open a new issue,\nIf you find a bug or mistake in the documentation, please open a new issue.\n\n\n\n\n\n","category":"module"},{"location":"tutorial/#Getting-Started-with-ESM","page":"Getting Started with ESM","title":"Getting Started with ESM","text":"This tutorial will walk you through the complete workflow of processing experimental data with ESM, from initial data exploration to final visualization. We'll use a sample flow cytometry dataset to demonstrate each step.","category":"section"},{"location":"tutorial/#Prerequisites","page":"Getting Started with ESM","title":"Prerequisites","text":"todo: Todo\nHow to install ESM (in particular the CLI)","category":"section"},{"location":"tutorial/#Step-1:-Explore-Your-Data","page":"Getting Started with ESM","title":"Step 1: Explore Your Data","text":"First, let's examine what data we have using the command line interface. We can use esm summarise on any ESM-compatible data file (.fcs, .esm, plate reader .txt, .tsv, .csv, etc.).\n\n# Navigate to your data directory\ncd /path/to/your/data\n\n# Get an overview of your data files (-p enables plotting)\nesm summarise data.fcs -p\n\nThis will show you some summary information about your data (number of samples, time ranges, etc.) and (since we enabled plotting with -p) it will produce a PDF file under the name data.fcs.pdf with plots of the data to explore.","category":"section"},{"location":"tutorial/#Step-2:-Create-a-Template-File","page":"Getting Started with ESM","title":"Step 2: Create a Template File","text":"Now let's create a template file that will define how to process your data:\n\n# Create a template for flow cytometry data\nesm template --output template.xlsx\n\nThis creates an Excel file called template.xlsx where we can provide ESM with extra information about your data.","category":"section"},{"location":"tutorial/#Step-3:-Fill-in-the-Template","page":"Getting Started with ESM","title":"Step 3: Fill in the Template","text":"We will provide an example of how we can fill in the Excel template file here. For a more in depth look, check out the Excel Interface.","category":"section"},{"location":"tutorial/#Step-3.1:-The-Samples-Sheet","page":"Getting Started with ESM","title":"Step 3.1: The Samples Sheet","text":"The first three columns control the final naming for the samples.\n\nThe type defines whether the data is \"plate reader\", \"flow\", or \"qpcr\" and how that file should be imported.\n\nThe data location gives the full filepath to the data.\n\nChannels identifies the specific channels that you would like to save in the ESM file. If left blank, then all will be saved.\n\nFinally, we have the plate reader brand. This identifies the format the data will be in. Available options are: \"spectramax\", \"biotek\", and \"tecan\". Leave it blank for other data types.\n\ntodo: todo\nFSC-H is no longer valid syntax. Now it needs to be FSC_H\n\n(Image: alt text)","category":"section"},{"location":"tutorial/#Step-3.2:-The-ID-Sheet","page":"Getting Started with ESM","title":"Step 3.2: The ID Sheet","text":"Here you can rename any channels. On the left, provide the channel name, as specified on the previous sheet. On the right, provide the new name for the channel. In this example, rather than using \"plate_01_a5.600\", we would then use \"plate_01_a5.od\".\n\n(Image: alt text)","category":"section"},{"location":"tutorial/#Step-3.3:-The-Groups-Sheet","page":"Getting Started with ESM","title":"Step 3.3: The Groups Sheet","text":"In this sheet, you can group samples together. For example, you may want to group all of your blank well together to make them easier to refer to.\n\nThere are a few formats for doing this. The simplest is to just write out all the samples in a comma separated list (i.e. \"plate_01_a1, plate_01_a2, plate_01_a3\").\n\nTo make this a bit shorter, you may choose to use the compressed format. In this format, anything specified in [] is expanded.\n\nMore details about the compressed format can be seen at Excel Interface\n\nHere, we use the compressed format so that:\n\nall wells on the left of a 96 well plate (A through H, column 1) are grouped as \"blank\",\nall wells on the right (A through H, column 12) are groups as \"control\",\nthe remaining wells (A through H, columns 2 through 11) are split into pairs of rows (A and B, C and D, E and F, G and H) into the groups \"ee01\", \"ee02\", \"ee03\", \"ee04\".\n\n(Image: alt text)","category":"section"},{"location":"tutorial/#Step-3.4:-The-Transformations-Sheet","page":"Getting Started with ESM","title":"Step 3.4: The Transformations Sheet","text":"On the transformations sheet, you can define the post-processing you want to apply to your data. This typically involves calibrations and calculating summary statistics.\n\nIn the example below, we calibrate our groups based on the blank group, then calculate growth rates on each of the calibrated transformations. Finally, the data is collected together (the \"processed\" variable appends the different DataFrames together) and this is normalised by the mean of the controls.\n\nMore details about some of the inbuilt methods in ESM, like growth_rate can be found in the Plate Reader, Flow Cytometry, and qPCR documentation.\n\ntodo: todo\nThe growth rate and calibration transformations are different to this\n\n(Image: alt text)","category":"section"},{"location":"tutorial/#Step-3.5:-The-Views-Sheet","page":"Getting Started with ESM","title":"Step 3.5: The Views Sheet","text":"Finally, the views describe a subset of transformations, groups and samples that you actually want to look at, outside of ESM. This is typically used for your final post-processed data, but can also be useful for debugging (viewing inputs and outputs from a transformation to make sure it is working as intended).\n\nIn the example below, we have a single view named \"growth_rate\", which uses the \"normalized\" transformation we defined previously.\n\n(Image: alt text)\n\ntip: Tip\nWe've gone through how to fill in the Excel template quite quickly. If you want more in depth information, try checking out the Excel Interface page which uses the same example, but goes into more details on what is allowed.","category":"section"},{"location":"tutorial/#Step-4:-Process-the-Data","page":"Getting Started with ESM","title":"Step 4: Process the Data","text":"Convert your template and data into an .esm file:\n\n# Translate the template and data into ESM format\nesm translate --excel template.xlsx --target data.esm\n\nThis will:\n\nRead all specified data files\nCombine results into a single ESM file","category":"section"},{"location":"tutorial/#Step-5:-Explore-the-Results","page":"Getting Started with ESM","title":"Step 5: Explore the Results","text":"We can now look at our calculated growth rates from our data.\n\n# Save the view to a .csv file\nesm views --esm-file experiment.esm","category":"section"},{"location":"tutorial/#Best-Practices","page":"Getting Started with ESM","title":"Best Practices","text":"Summarise Data Early: Looking at plots of the data can help identify issues like contaminated wells, that may change how you want to analyse the data.\nStart Small: Its easy to fill out the template at the start, but this can make it harder to debug the transformations. Try going through, writing a transformation at a time and export it as a view to keep an eye on whats happening.\nClose Excel: .xlsx files behave differently if they are open vs. closed and esm translate will only work properly if you don't have the template open at the same time.\nRemember the order of ESM operations: Using esm translate will import and check your raw data, and collect groups, but it won't check your transformations and views. If you are getting errors when trying to generate views, this may be due to transformations being incorrectly defined, rather than just your views.","category":"section"},{"location":"tutorial/#Next-Steps","page":"Getting Started with ESM","title":"Next Steps","text":"Now that you've processed your data with ESM, you can:\n\nPerform statistical analysis using the post-processed data\nCreate publication-quality plots\nShare ESM files with collaborators or as supplementary material\nIntegrate with computational pipelines\n\nIf you want to learn more about ESM, you can go to:\n\nPlate Readers to learn about the functionality and different methods available for working with plate reader data.\nFlow Cytometry to learn about the calibration and gating methods available for working with flow cytometry data.\nqPCR to learn about the methods available for working with qPCR data.\nCommand Line Interface to learn about all the features of the command line interface (esm summarise, esm translate, etc.).\nData Format to learn about how .esm files are structured.\nExcel Interface to learn more details about how the Excel template file works and its format.","category":"section"},{"location":"tutorial/#Getting-Help","page":"Getting Started with ESM","title":"Getting Help","text":"If you encounter issues, open a new issue with details about your problem.","category":"section"}]
}
